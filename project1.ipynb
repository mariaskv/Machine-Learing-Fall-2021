{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Skevofylaka_111520190073.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1JQtz4f0ZuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49065a56-413c-4e1e-d433-876931b8679c"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import random\n",
        "import sys\n",
        "\n",
        "random.seed(173) #The last four digits of my number are 0173 but seems to exist a problem with 0.\n",
        "\n",
        "#i\n",
        "X = random.randint(random.randint(0, 10), size=(3,4))\n",
        "Y = random.randint(random.randint(0, 10), size=(4,3))\n",
        "print(\"X=\",X)\n",
        "print(\"Y=\",Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X= [[4 3 0 3]\n",
            " [2 1 2 1]\n",
            " [3 3 1 3]]\n",
            "Y= [[1 2 1]\n",
            " [3 1 1]\n",
            " [4 4 1]\n",
            " [0 0 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn3uxvT6BdIO"
      },
      "source": [
        "#ii\n",
        "a = random.randint(random.randint(0, 10), size=(4))\n",
        "b = random.randint(random.randint(0, 10), size=(4))\n",
        "print(\"a=\", a)\n",
        "print(\"b=\",b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9luO23YBgJ7"
      },
      "source": [
        "#1.1\n",
        "c = np.inner(a,b)\n",
        "print(\"c=\",c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVOYiQ0KXOYR"
      },
      "source": [
        "Αναλυτικός υπολογισμός του εσωτερικού γινομένου: \n",
        "\n",
        "a = (x1, y1, z1, v1)\n",
        "\n",
        "b = (x2, y2, z2, v2)\n",
        "\n",
        "<a,b> = x1 * x2 + y1 * y2 + z1 * z2 + v1 * v2 \n",
        "\n",
        "Τα αποτελέσματα φαίνεται να επιβεβαιώνονται από τον παραπάνω κώδικα"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--OxIDz1BkGB",
        "outputId": "74cea8c3-05a6-4545-e4e1-a29ffc60a72a"
      },
      "source": [
        "#1.2\n",
        "d = np.dot(X,a)\n",
        "print(\"d=\", d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d= [ 784 1138  912]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zMBqvT1ZysQ"
      },
      "source": [
        "Έστω ένας πίνακας Χ = [ χ11, χ12, χ13, χ14\n",
        "                        χ21, χ22, χ23, χ24\n",
        "                        χ31, χ32, χ33, χ34 ]\n",
        "\n",
        "και ένα διάνυσμα α = [ α1, α2, α3, α4]\n",
        "\n",
        "Τότε το γινόμενο Χ*α είναι ίσο με:\n",
        "\n",
        "= [α1 * χ11 + α1 * χ12 + α1 * χ13 + α1 * χ14, α2 * χ21 + α2 * χ22 + α2 * χ23 + α2 * χ24, α3 * χ31 + α3 * χ32 + α3 * χ33 + α3 * χ34]  \n",
        "\n",
        "Το οποίο επιβεβαιώνεται από τον παραπάνω κώδικα.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by9C-frIBnpf"
      },
      "source": [
        "#1.3\n",
        "e = np.dot(X, Y)\n",
        "print(\"e=\", e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0ddrCQoeIoV"
      },
      "source": [
        "Έστω ένας πίνακας Χ = [ χ11, χ12, χ13, χ14\n",
        "                        χ21, χ22, χ23, χ24\n",
        "                        χ31, χ32, χ33, χ34 ]\n",
        "\n",
        "Έστω ένας πίνακας Υ = [ y11, y12, y13\n",
        "                        y21, y22, y23\n",
        "                        y31, y32, y33\n",
        "                        y41, y42, y43 ]\n",
        "\n",
        "Τότε το γινόμενο X*Y ισόυται με έναν πίνακα διάστασης 3 * 3 που υπολογίζεται ως:\n",
        "\n",
        "XY = [ \n",
        "\n",
        "  x11 * y11 + x12 * y21 + x13 * y31 + x14 * y41, x11 * y12 + x12 * y22 + x13 * y32 + x14 * y42, x11 * y13 + x12 * y23 + x13 * y33 + x14 * y43\n",
        "\n",
        "  x21 * y11 + x22 * y21 + x23 * y31 + x24 * y41, x12 * y12 + x22 * y22 + x23 * y32 + x24 * y42, x12 * y13 + x22 * y23 + x23 * y33 + x24 * y43\n",
        "\n",
        "  x31 * y11 + x32 * y21 + x33 * y31 + x34 * y41, x31 * y12 + x32 * y22 + x33 * y32 + x34 * y42, x31 * y13 + x32 * y23 + x33 * y33 + x34 * y43 ]\n",
        "\n",
        "το οποίο αποδυκνείεται από τον παραπάνω κώδικα."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFRb5o5gB_xA",
        "outputId": "42da620c-356c-4399-fcbc-535fce51e242"
      },
      "source": [
        "#1.4\n",
        "norm = np.linalg.norm(a)\n",
        "print(\"norm=\", norm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "norm= 20.639767440550294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwfHg89hjo1F"
      },
      "source": [
        "Έστω ένα διάνυσμα: α = (α1, α2, α3, α4)\n",
        "\n",
        "Η νόρμα του διανύσματος υπολογίζεται ως:\n",
        "\n",
        "τετραγωνική_ρίζα(α1 * α1 + α2 * α2 + α3 * α3 + α4 * α4)\n",
        "\n",
        "Το οποίο επιβεβαιώνεται από τον παραπάνω κώδικα.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T-sbAG-DMH0",
        "outputId": "adfe0d79-8d13-42b7-cc24-f1d47d1f1850"
      },
      "source": [
        "#1.5\n",
        "norm_fb = np.linalg.norm(X)\n",
        "print(\"norm_fb=\", norm_fb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "norm_fb= 51.85556864985669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXazbBjbknQN"
      },
      "source": [
        "Έστω ένας πίνακας Χ = [ χ11, χ12, χ13, χ14\n",
        "                        χ21, χ22, χ23, χ24\n",
        "                        χ31, χ32, χ33, χ34 ]\n",
        "\n",
        "H Frobenius νόρμα του χ υπολογίζεται ως: ρίζα(Σ(i=1,4)Σ(j=1,3)(xij*xij))\n",
        "\n",
        "το οποίο αποδεικνύεται από τον παραπάνω κώδικα."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5XrSeFFHYsx"
      },
      "source": [
        "#2.1\n",
        "\n",
        "H παράγωγος της συνάρτησης: $ f(x) = x^TAx + b^Tx $ ισούται με το άθροισμα των παραγώγων τως συναρτήσεων: $ g(x) = x^TAx $ και $ h(x) = b^Tx $.\n",
        "\n",
        "Για τις οποίες ισχύει:\n",
        "\n",
        "$ h(x)  = x^Tb = \t\\begin{bmatrix}x1 & .. & xn \\end{bmatrix} \\begin{bmatrix}b1\\\\ .. \\\\ bn \\end{bmatrix} = b1*x1 + .. + bn*xn $ \\\\ \\\\\n",
        "\n",
        "Συνεπώς για την παράγωγο ισχύει: \\\\ \\\\\n",
        "\n",
        "$ \\frac{\\partial x^Tb}{\\partial x} = \n",
        "\\begin{bmatrix} \\frac{\\partial x^Tb}{\\partial x1} \\\\ ..\\\\ \\frac{\\partial x^Tb}{\\partial xn} \\end{bmatrix} \n",
        "= \\begin{bmatrix} \\frac{\\partial (b1x1+..+bnxn)}{\\partial x1} \\\\ ..\\\\ \\frac{\\partial (b1x1+..+bnxn)}{\\partial xn} \\end{bmatrix}\n",
        "= \\begin{bmatrix}b1\\\\ .. \\\\ bn \\end{bmatrix}\n",
        "= b $\n",
        "\n",
        "Για την g(x) έχουμε: \n",
        "\n",
        "$ g(x) = x^TAx = \\begin{bmatrix}x1 & .. & xn \\end{bmatrix}\\begin{bmatrix}a11 & .. & a1n \\\\ .. & .. & .. \\\\ an1 & .. &ann \\end{bmatrix}\\begin{bmatrix}x1 \\\\ .. \\\\ xn \\end{bmatrix} \n",
        "= \\begin{bmatrix}(a11x1 + .. + an1xn) & .. & (a1nx1 + .. + annxn)\\end{bmatrix}\\begin{bmatrix}x1 \\\\s .. \\\\ xn \\end{bmatrix} \\\\ \n",
        "= \\begin{bmatrix}\\sum_{i=1}^{n}ai1xi & .. & \\sum_{i=1}^{n}ainxi \\end{bmatrix}\\begin{bmatrix}x1 \\\\ .. \\\\ xn \\end{bmatrix} \\\\ \n",
        "= x1\\sum_{i=1}^{n}ai1xi + .. + xn\\sum_{i=1}^{n}ainxi \\\\ \n",
        "= \\sum_{j=1}^{n} xj \\sum_{i=1}^{n}aijxi \\\\ \n",
        "= \\sum_{j=1}^{n}\\sum_{i=1}^{n}aijxixj $ \\\\ \n",
        "\n",
        "Για την παράγωγο ισχύει: \n",
        "\n",
        "$ \\frac{\\partial x^TAx}{\\partial x} = \\begin{bmatrix}\\frac{\\partial x^TAx}{\\partial x1} \\\\ .. \\\\ \\frac{\\partial x^TAx}{\\partial xn} \\end{bmatrix}$\n",
        "\n",
        "Για την k-ιοστή σειρά του πίνακα ισχύει: \n",
        "\n",
        "$ \\frac{\\partial x^TAx}{\\partial xk} =\\\\\n",
        "= \\frac{\\partial}{\\partial xk}\\sum_{j=1}^{n}\\sum_{i=1}^{n}aijxixj \\\\\n",
        "=\\frac{\\partial}{\\partial xk}(x1*\\sum_{i=1}^{n}ai1xi\n",
        "+ .. + xn*\\sum_{i=1}^{n}ainxi) \\\\ \n",
        "= \\sum_{j=1}^{n}akjxj + \\sum_{i=1}^{n}aikxi \\\\ \n",
        "= (k^{th} row of A)x + (transpose of k^{th} column of A)x \\\\ \n",
        "= [(k^{th} row of A) + (transpose of k^{th} column of A)]x $ \\\\ \n",
        "\n",
        "Συνεπώς:\n",
        "\n",
        "$ \\frac{\\partial x^TAx}{\\partial x} = \\\\ \n",
        "= \\begin{bmatrix}[(1^{st} row of A) + (transpose of 1{st} column of A)]x \\\\ .. \\\\ [(n^{th} row of A) + (transpose of n{th} column of A)]x \\end{bmatrix}   \\\\\n",
        "= (\\begin{bmatrix} 1^{st} row of A \\\\ .. \\\\ n^{th} row of A \\end{bmatrix} + \\begin{bmatrix} transpose of 1^{st} column of A \\\\ .. \\\\ transpose of n^{th} column of A \\end{bmatrix})x \\\\ \n",
        "= (A + A^T)x $ \\\\\n",
        "\n",
        "Και επειδή ο πίνακας Α είναι συμμετρικός έχουμε: \n",
        "\n",
        "$ \\frac{\\partial x^TAx}{\\partial x} = 2Ax $ \n",
        "\n",
        "Συνεπώς η παράγωγος: \n",
        "\n",
        "$ \\frac{\\partial (x^TAx + b^Tx)}{\\partial x} = 2Ax + b $ \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buOG0uo6pbc-"
      },
      "source": [
        "#2.2\n",
        "Έστω η συνάρτηση: $ l(w) = |A - XB| $\n",
        "\n",
        "Για να υπολογιστεί το ελάχιστο της συνάρτησης ως προς Χ αρκεί να υπολογιστεί η πρώτη παράγωγος και να τεθεί ίση με 0.\n",
        "\n",
        "$ minRSS = minl(w) = min|A - XB| \\\\\n",
        "  l(w) = |A - XB| = (A - XB)^T(A - XB) $\n",
        "\n",
        "Για την παράγωγο:\n",
        "\n",
        "$ \\frac{\\partial l(X)}{\\partial X} = -2X^TA - XB \\\\\n",
        "  0 = -2X^T(A - XB) \\\\\n",
        "  0 = X^T(A - XB) \\\\\n",
        "  0 = X^TA - X^TXB \\\\ $\n",
        "\n",
        "Άρα: \n",
        "\n",
        "$ X^TA = X^TXB $ \\\\\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siUBrHznftGM"
      },
      "source": [
        "#3.1.1\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def gradient_descent1(gradient, gradient2, x1, x2, fx, learning_rate, T):\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.ylabel(\"Function\");plt.xlabel(\"i value\")\n",
        "  for i in range(0, T, 1):\n",
        "    x1 = x1 - learning_rate*gradient(x1)\n",
        "    x2 = x2 - learning_rate*gradient2(x2)\n",
        "    res = fx(x1, x2)\n",
        "    plt.scatter(i, res)\n",
        "  plt.show()\n",
        "\n",
        "def fx1(x1, x2):\n",
        "  return (x1 - 2)**2 + (x2 - 3)**2\n",
        "\n",
        "def gradient_x1_1(x1):\n",
        "  return 2*(x1 - 2)\n",
        "\n",
        "def gradient_x2_1(x2):\n",
        "  return 2*(x2 - 3)\n",
        "\n",
        "x1 = 0\n",
        "x2 = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18Ic9rA6NZ81"
      },
      "source": [
        "gradient_descent1(gradient_x1_1, gradient_x2_1, x1, x2, fx1, 0.5, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm03JC5FQDDB"
      },
      "source": [
        "Για learing_rate = 0.5 και 10 επαναλήψεις ο αλγόριθμος φαίνεται να δουλεύει και η συνάρτηση f1(x) συγκλινει σε μία ευθεία. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR50nucpNeXj"
      },
      "source": [
        "for a in np.arange(0.1, 0.9, 0.3):\n",
        "  for T in range(10, 60, 20):\n",
        "    print(\"a:\", a, \"T:\", T)\n",
        "    gradient_descent1(gradient_x1_1, gradient_x2_1, x1, x2, fx1, a, T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzbrMUwkQTfl"
      },
      "source": [
        "Με τις παραπάνω εντολές καλείται ο αλγόριθμος gradient descent για την f1(x) για διάφορες τιμές του learning_rate και διαφορετικό αριθμό επαναλήψεων. \\\\\n",
        "Για learning_rate = 0.1 η συνάρτηση φαίνεται να συγκλινει για πάνω από 50 επαναλήψεις. \n",
        "\n",
        "Για learning_rate = 0.4 η συνάρτηση φαίνεται να συγκλινει για πάνω από 10 επαναλήψεις. \n",
        "\n",
        "Για learning_rate = 0.7 η συνάρτηση φαίνεται να συγκλινει για πάνω από 30 επαναλήψεις. \n",
        "\n",
        "Συνολικά ο αλγόριθμος φαίνεται να συμπεριφέρεται καλύτερα για learning_rate = 0.4 όπου αρκούν μόνο 10 επαναλήψεις για να συγκλινει.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo9Zcr-tUtPd"
      },
      "source": [
        "gradient_descent1(gradient_x1_1, gradient_x2_1, x1, x2, fx1, 0.001, 30)\n",
        "gradient_descent1(gradient_x1_1, gradient_x2_1, x1, x2, fx1, 0.007, 30)\n",
        "gradient_descent1(gradient_x1_1, gradient_x2_1, x1, x2, fx1, 0.015, 30)\n",
        "\n",
        "gradient_descent1(gradient_x1_1, gradient_x2_1, x1, x2, fx1, 1.2, 30)\n",
        "gradient_descent1(gradient_x1_1, gradient_x2_1, x1, x2, fx1, 2.3, 30)\n",
        "gradient_descent1(gradient_x1_1, gradient_x2_1, x1, x2, fx1, 5, 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtuegNEqVgIs"
      },
      "source": [
        "Με τις παραπάνω εντολές δοκιμάζουμε τον αλγόριθμο με κάποιες μεγάλες και κάποιες μικρές τιμές του learning rate. Για μικρές τιμές βλέπουμε ότι η συνάρτηση έχει αρνητική κλίση και όσο μεγαλώνει εμφανίζεται μια μικρή κοιλότητα. Όταν το learning_rate γίνει μεγάλο η συνάρτηση πλέον είναι μια ευθεία γραμμή η οποία δεν μεταβάλλεται. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfvEeUatrHyw"
      },
      "source": [
        "#3.1.2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def gradient_descent2(gradient, gradient2, x1, x2, fx, learning_rate, T):\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.ylabel(\"Function\");plt.xlabel(\"i value\")\n",
        "  for i in range(0, T, 1):\n",
        "    x1 = x1 - learning_rate*gradient(x1, x2)\n",
        "    x2 = x2 - learning_rate*gradient2(x1, x2)\n",
        "    res = fx(x1, x2)\n",
        "    plt.scatter(i, res)\n",
        "    plt.plot(res, i)\n",
        "  plt.show()\n",
        "\n",
        "def fx2(x1, x2):\n",
        "  return (1 - (x2 - 3))**2 + 20*((x1 + 3) - ((x2 - 3)**2))**2\n",
        "\n",
        "def gradient_x1_2(x1, x2): \n",
        "  return 40*((x1 + 3) - (x2 - 3)**2)\n",
        "\n",
        "def gradient_x2_2(x1, x2):\n",
        "  return 2*(1 - (x2 - 3)) - 80*((x1 + 3) - (x2 - 3)**2)*(x2 - 3)\n",
        "\n",
        "x1 = 0\n",
        "x2 = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDim4vmcNHeo"
      },
      "source": [
        "gradient_descent2(gradient_x1_2, gradient_x2_2, x1, x2, fx2, 0.5, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua4YhZ_rR9kg"
      },
      "source": [
        "Για learing_rate = 0.5 και 10 επαναλήψεις ο αλγόριθμος φαίνεται να μην δουλεύει και να οδηγεί σε overflow για την συνάρτηση f2(x). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4puOPqkmNLh7"
      },
      "source": [
        "for a in np.arange(0.001, 0.009, 0.003):\n",
        "  for T in range(10, 60, 20):\n",
        "    print(\"a:\", a, \"T:\", T)\n",
        "    gradient_descent2(gradient_x1_2, gradient_x2_2, x1, x2, fx2, a, T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbzQltLjS3e8"
      },
      "source": [
        "Με τις παραπάνω εντολές καλείται ο αλγόριθμος gradient descent για την f2(x) για διάφορες τιμές του learning_rate και διαφορετικό αριθμό επαναλήψεων. \\\\\n",
        "Για learning_rate = 0.001 η συνάρτηση φαίνεται να συγκλινει για πάνω από 30 επαναλήψεις. \n",
        "\n",
        "Για learning_rate = 0.004 η συνάρτηση φαίνεται να συγκλινει για πάνω από 50 επαναλήψεις ενώ τα σημεία είναι αρκετά άστατα. \n",
        "\n",
        "Για learning_rate >= 0.007 η συνάρτηση φαίνεται να οδηγεί σε overflow \n",
        "\n",
        "Συνολικά ο αλγόριθμος φαίνεται να συμπεριφέρεται καλύτερα για learning_rate = 0.001 όπου αρκούν μόνο 30 επαναλήψεις για να συγκλινει.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrOMDXw6Weh0"
      },
      "source": [
        "gradient_descent2(gradient_x1_2, gradient_x2_2, x1, x2, fx2, 0.0001, 30)\n",
        "gradient_descent2(gradient_x1_2, gradient_x2_2, x1, x2, fx2, 0.0009, 30)\n",
        "gradient_descent2(gradient_x1_2, gradient_x2_2, x1, x2, fx2, 0.0015, 30)\n",
        "\n",
        "gradient_descent2(gradient_x1_2, gradient_x2_2, x1, x2, fx2, 1, 30)\n",
        "gradient_descent2(gradient_x1_2, gradient_x2_2, x1, x2, fx2, 2, 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMWrxu_HWvqq"
      },
      "source": [
        "Με τις παραπάνω εντολές δοκιμάζουμε τον αλγόριθμο με κάποιες μεγάλες και κάποιες μικρές τιμές του learning rate. Για μικρές τιμές η συνάρτηση έχει αρνητική κλίση και φαίνεται να συγκεντρώνεται γύρω από το 0 όπου για learning_rate = 0.0009 είναι μία ευθεία γραμμή. Για μεγάλες τιμές η συνάρτηση οδηγεί σε overflow και δεν έχουμε αποτέλεσμα."
      ]
    }
  ]
}